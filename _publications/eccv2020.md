---
title: "Globally-Optimal Event Camera Motion Estimation"
author: "Xin Peng\\*, <b>Yifu Wang</b>\\*, Ling Gao\\* and Laurent Kneip."
collection: publications
permalink: /eccv2020
excerpt: 
date: 2020-08-23
venue: European Conference on Computer Vision
paperurl: https://link.springer.com/chapter/10.1007/978-3-030-58574-7_4
citation: 
youtubeId: 
header:
   teaser: eccv2020_t.png
---

<a href="https://1fwang.github.io/files/eccv2020.pdf" target="_blank"><b>[PDF]</b></a>&emsp;
<a href="https://1fwang.github.io/files/peng2020globally.txt" target="_blank"><b>[BibTex]</b></a>

![firenet_banner](/images/tpami2020.png){:class="img-responsive"}

<b>Abstract.</b> 
Event cameras are bio-inspired sensors that perform well in HDR conditions and have high temporal resolution. However, different from traditional frame-based cameras, event cameras measure asynchronous pixel-level brightness changes and return them in a highly discretised format, hence new algorithms are needed. The present paper looks at fronto-parallel motion estimation of an event camera. The flow of the events is modeled by a general homographic warping in a space-time volume, and the objective is formulated as a maximisation of contrast within the image of unwarped events. However, in stark contrast to prior art, we derive a globally optimal solution to this generally non-convex problem, and thus remove the dependency on a good initial guess. Our algorithm relies on branch-and-bound optimisation for which we derive novel, recursive upper and lower bounds for six different contrast estimation functions. The practical validity of our approach is supported by a highly successful application to AGV motion estimation with a downward facing event camera, a challenging scenario in which the sensor experiences fronto-parallel motion in front of noisy, fast moving textures.

<b>Reference:</b>
* Peng, X., Wang, Y., Gao, L. and Kneip, L., 2020, August. Globally-Optimal Event Camera Motion Estimation. In European Conference on Computer Vision (pp. 51-67). Springer, Cham.
